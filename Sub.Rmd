---
title: "A machine learning approach to evaluate exercise performance"
author: "JMW0103"
date: "Thursday, September 17, 2015"
output: html_document
---
Load the required packages for this analysis
```{r warning=FALSE, message=FALSE }
library(digest)
library(caret)
library(randomForest)
set.seed(91295)
```

# Obtain and Load the Data

The correct data sets are required for this analysis:  
1) a set of data >19000 instances from  **https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv**   
2) a set of test instances for _automatic_  __evaluation of the model__  **https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv** (auto_TestSet).

```{r message=FALSE,results='hide'}
library(digest)
if(file.exists("pml-training.csv")&&(identical(digest("pml-training.csv",file=TRUE),"56926c78af383dcdc2060407942e52e9"))){   
} else{  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")}

if(file.exists("pml-testing.csv")&&(identical(digest("pml-testing.csv",file=TRUE),"bc4174f3ec5dfcc5c570a1d2709272d9"))){   
} else{  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv") }
```
Manual inspection of the training data set indicates 3 distinct labels for data not available : **"NA", ""** and **"#DIV/0!"**
Read the data sets into data frames, using the above strings to indicate NA in the dataframe.  
```{r}
baseData<-read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!",""))
auto_TestSet<-read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
```

# Clean and Preprocess the Data Sets.

Determine the cleaning and pre-processing drequired of the data sets:


* Fields 1-7 are codes for participants and other data which can produce spurious overfitting  
        + remove from in the training data and test set

* determine all fields where >5% of entries are NA  
        + remove these columns from the training data and test set
        
Partition the coded training data into a working training set and a test set for final evaluation of the best performing method.        

```{r}
# Determine and apply data cleaning criteria
numInst<-length(baseData[,1])
baseStrip_1<-baseData[,-(1:7)] ; 
auto_testStrip_1<-auto_TestSet[,-(1:7)]
na_level<-colSums((is.na(baseStrip_1))/numInst)<0.05
trainData<-baseStrip_1[,na_level] ; 
auto_testStrip_2<-auto_testStrip_1[,na_level]
# partition the coded data into a working training set and the final test set
trainSetindex <- createDataPartition(y = trainData[,ncol(trainData)], p = 0.70, list = FALSE)
trainSet<-trainData[trainSetindex,]
testSet<-trainData[-trainSetindex,]
```

There are `r length(trainSet[,1])` instances in the training data and `r length(trainSet[,1])` in the test set.    

Preprocess the data set to optimize range, distribution etc.  
Remove the class identifiers from the data.

```{r}
ppc<-preProcess(trainSet[,-ncol(trainSet)],method=c("BoxCox","center","scale"))
ds<-predict(ppc,trainSet[,-ncol(trainSet)])
```

Perform PCA (Principal Component Analysis) and determine approx number of components required to optimize variance coverage (first 95% of variance).

```{r}
pca<-prcomp(ds)
cumSumms<-cumsum(100*pca$sdev^2)/sum(pca$sdev^2)
numComp<-sum(cumSumms<95)+1
```
As shown in the following figure, `r numComp` components account for 95% of the variance:
```{r}
plot((cumsum(100*pca$sdev^2)/sum(pca$sdev^2)), xlab="principal component",
ylab="cummulative %(variance)", type="b", pch=9,ylim=c(0,100))
```

 **Principal Component Analysis of data in the training data set.**

 The classification codes were removed, along with the first 7 elements of each observation. The remaining variables were subjected to the BoxCox transformation to approximate normal distribuion, then centred and scaled. Robust imputation was ensured by removing all columns with more than 5% missing values. The cummulative variance accounted for by the components calculated by PCA are shown. 95% of variance is accounted for by the first `r numComp` components. 


Use the preprocess function to transform the training and test data

```{r}
ppc2<-preProcess(trainSet[,-ncol(trainSet)],method=c("BoxCox","center","scale","pca"),pcaComp=numComp)
reduced_trSet<-predict(ppc2,trainSet[,-ncol(trainSet)])
reduced_trSet[ncol(reduced_trSet)+1]<-trainSet[,ncol(trainSet)]
reduced_testSet<-predict(ppc2,testSet[,-ncol(testSet)])
reduced_testSet[ncol(reduced_testSet)+1]<-testSet[,ncol(testSet)]

```
   
Define a function to automate the running and comparisons of a range of machine learning methods, ustilising the *train* method of the  **caret** package.  

```{r}
runTrain<-function(data,method,seed=6543){
   library(caret)
   set.seed(seed)
# shuffle the data by row  
   data <- data[sample(nrow(data)),]
# extract a temporary training and test set  
   trainSetindex <- createDataPartition(y = data[,ncol(data)], p = 0.75, list = FALSE)
   trainSet<-data[trainSetindex,]
   redTrSet<-trainSet[,-ncol(trainSet)]
   TrKey<-trainSet[,ncol(trainSet)]
   tSet<-data[-trainSetindex,] 
   redTeSet<-tSet[,-ncol(tSet)]
   TeKey<-tSet[,ncol(tSet)]
# create file name for model
   file = paste(method,".mdl",sep="")
# train the model 
   trainedModel<-train(redTrSet,TrKey,method=method)
   save(trainedModel,file=file)
# predict from the test set
   predicted<-predict(trainedModel,newdata=redTeSet)
# confusion matrix:
   matx<-confusionMatrix(predicted,TeKey)
# save the confusion Matrix
   save(matx,file=paste(method,".cfm",sep=""))
# construct a return string
   returnTxt<-paste("\nmodel =",file,"length of processing =",sprintf("%.1f",trainedModel$times$everything["elapsed"])," seconds",sep=" ")
   returnTxt<-paste(returnTxt,"","PERFORMANCE","===========","",sep="\n") 
   v<-paste(capture.output(matx),collapse="\n")

   returnTxt<-paste(returnTxt,v)
   cat(returnTxt)
}
```

```{r}
#methods<-c("rpart","lda","svmRadial","rf")
methods<-c("lda","lda")
best<-0;
meth<-""
seeds<-c(1496,1776,1812,1969)
for(i in seq_along(methods)){
    summy<-runTrain(reduced_trSet,methods[i],seed=seeds[i])  
    load(paste(methods[i],".cfm",sep=""))
    if(matx$overall['Accuracy']>best){
       best<-matx$overall['Accuracy']
       meth<-methods[i]
    }
    summy
}

outtext<-paste("\nThe best method tried is ",meth," with an accuracy of ",best,".\n\n")
cat(outtext)
```
