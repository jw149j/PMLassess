---
title: "A machine learning approach to evaluate exercise performance"
author: "JMW0103"
date: "Thursday, September 17, 2015"
output: html_document
---
### Executive Summary.

A group of volunteers were trained to perform a series of supervised exercises with weights, involving a number of defined 'mistakes' in technique. Each performance was recorded using a series of accelerometers attached to a number of locations on the body, and a range of values recorded. The purpose of this analysis is to determine a machine learning model which can consistently determine the mode of exercise (i.e. which specific 'mistake' is being performed) from a novel set of accelerometer readings.
The experiment is described in detail [here](http://http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf).
The analysis concluded that a random forest model produced a good predictive model, but required major system resources ( as indicated by time to complete the model building).   



**Load the required packages for this analysis**
```{r warning=FALSE, message=FALSE }
library(digest)
library(caret)
library(randomForest)
library(kernlab)
set.seed(91295)
```

## Obtain and Load the Data

The correct data sets are required for this analysis:  
1) a set of data >19000 instances from  [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)   
2) a set of test instances for _automatic_  __evaluation of the model__  [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv) (auto_TestSet).

```{r message=FALSE,results='hide'}
library(digest)
if(file.exists("pml-training.csv")&&(identical(digest("pml-training.csv",file=TRUE),"56926c78af383dcdc2060407942e52e9"))){   
} else{  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","pml-training.csv")}

if(file.exists("pml-testing.csv")&&(identical(digest("pml-testing.csv",file=TRUE),"bc4174f3ec5dfcc5c570a1d2709272d9"))){   
} else{  download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","pml-testing.csv") }
```
Manual inspection of the training data set indicates 3 distinct labels for data not available : **"NA", ""** and **"#DIV/0!"**
Read the data sets into data frames, using the above strings to indicate NA in the dataframe.  
```{r}
baseData<-read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!",""))
auto_TestSet<-read.csv("pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
```

## Clean and Preprocess the Data Sets.

Determine the cleaning and pre-processing required of the data sets:


* Fields 1-7 are codes for participants and other data which can produce spurious overfitting  
        + remove from in the training data and test set

* determine all fields where >5% of entries are NA  
        + remove these columns from the training data and test set
        
Partition the coded training data into a working training set and a test set for final evaluation of the best performing method.        

```{r}
# Determine and apply data cleaning criteria
numInst<-length(baseData[,1])
baseStrip_1<-baseData[,-(1:7)] ; 
auto_testStrip_1<-auto_TestSet[,-(1:7)]
na_level<-colSums((is.na(baseStrip_1))/numInst)<0.05
trainData<-baseStrip_1[,na_level] ; 
auto_testStrip_2<-auto_testStrip_1[,na_level]
# partition the coded data into a working training set and the final test set
trainSetindex <- createDataPartition(y = trainData[,ncol(trainData)], p = 0.70, list = FALSE)
trainSet<-trainData[trainSetindex,]
testSet<-trainData[-trainSetindex,]
```

There are `r length(trainSet[,1])` instances in the training data and `r length(testSet[,1])` in the test set.    

Preprocess the data set to optimize range, distribution etc.  
Remove the class identifiers from the data.

```{r}
ppc<-preProcess(trainSet[,-ncol(trainSet)],method=c("BoxCox","center","scale"))
ds<-predict(ppc,trainSet[,-ncol(trainSet)])
```

Perform PCA (Principal Component Analysis) and determine approx number of components required to optimize variance coverage (first 95% of variance).

```{r}
pca<-prcomp(ds)
cumSumms<-cumsum(100*pca$sdev^2)/sum(pca$sdev^2)
numComp<-sum(cumSumms<95)+1
```
As shown in the following figure, `r numComp` components account for 95% of the variance:
```{r}
plot((cumsum(100*pca$sdev^2)/sum(pca$sdev^2)), xlab="principal component",
ylab="cummulative %(variance)", type="b", pch=9,ylim=c(0,100))
```

 **FIG1. Principal Component Analysis of data in the training data set.**

 The classification codes were removed, along with the first 7 elements of each observation. The remaining variables were subjected to the BoxCox transformation to approximate normal distribuion, then centred and scaled. Robust imputation was ensured by removing all columns with more than 5% missing values. The cummulative variance accounted for by the components calculated by PCA are shown. 95% of variance is accounted for by the first `r numComp` components. 


Use the preprocess function to transform the training and test data

```{r}
ppc2<-preProcess(trainSet[,-ncol(trainSet)],method=c("BoxCox","center","scale","pca"),pcaComp=numComp)
reduced_trSet<-predict(ppc2,trainSet[,-ncol(trainSet)])
reduced_trSet[,ncol(reduced_trSet)+1]<-trainSet[,ncol(trainSet)]
reduced_testSet<-predict(ppc2,testSet[,-ncol(testSet)])
reduced_testSet[,ncol(reduced_testSet)+1]<-testSet[,ncol(testSet)]
auto_testPCA<-predict(ppc2,auto_testStrip_2[,-ncol(auto_testStrip_2)])

```

## Test the performance of a set of machine learning algorithms applied to the test datset.

### Benchmark  

The benchmark level of discrimination is determined by randomising the vector of class values for the training set: maintaining the proportions of the classes but effectively randomly selecting them. 

    
```{r}
   class<-reduced_trSet[,ncol(reduced_trSet)]
   random<-sample(class)
   matx<-confusionMatrix(random,class)
   v<-paste(capture.output(matx),collapse="\n")
   cat(v)
   
```                        
This demonstates an overall accuaracy of **`r round(matx$overall['Accuracy'],3)`**  with an average 'by class' balanced accuracy of  **`r round(mean(matx$byClass[,8]),3)`**.  
   
##Test a panel of machine learning algorithms 

Define a function to automate the running and comparisons of a range of machine learning methods, utilising the _**train()**_ method of the  **caret** package. The algorithms are assessed in terms of the overall and 'by class' balanced accuracy, and by the time required to complete the algorithm.

```{r}
runTrain<-function(data,method,seed=6543){
   library(caret)
   set.seed(seed)
# shuffle the data by row  
   data <- data[sample(nrow(data)),]
# extract a temporary training and test set  
   trainSetindex <- createDataPartition(y = data[,ncol(data)], p = 0.75, list = FALSE)
   trainSet<-data[trainSetindex,]
   redTrSet<-trainSet[,-ncol(trainSet)]
   TrKey<-trainSet[,ncol(trainSet)]
   tSet<-data[-trainSetindex,] 
   redTeSet<-tSet[,-ncol(tSet)]
   TeKey<-tSet[,ncol(tSet)]
# create file name for model
   file = paste(method,".mdl",sep="")
# train the model 
   trainedModel<-train(redTrSet,TrKey,method=method)
   save(trainedModel,file=file)
# predict from the test set
   predicted<-predict(trainedModel,newdata=redTeSet)
# confusion matrix:
   matx<-confusionMatrix(predicted,TeKey)
# save the confusion Matrix
   save(matx,file=paste(method,".cfm",sep=""))
# save the confusion Matrix
save(matx,file=paste(method,".cfm",sep=""))
# construct a return string
returnTxt<-paste("\n====================================================\n","model =",file,"length of processing =",sprintf("%.1f",trainedModel$times$everything["elapsed"])," seconds\n",sep=" ")
returnTxt<-paste(returnTxt,"","PERFORMANCE","===========","",sep="\n")
returnTxt<-paste(returnTxt,"Overall accuracy\n",round(matx$overall['Accuracy'],3),"\n","By Class Balanced Accuracy","\n",sep="")
cat(returnTxt)
cat(paste(names(matx$byClass[,8]),sep="\t")); cat("\n")
cat(paste(round(matx$byClass[,8],3),sep="\t    \t")); cat("\n")
}

```

```{r}
#methods<-c("rpart","lda","svmRadial","rf")
methods<-c("lda","lda")
best<-0;
meth<-""
seeds<-c(1496,1776,1812,1969)
for(i in seq_along(methods)){
    summy<-runTrain(reduced_trSet,methods[i],seed=seeds[i])  
    load(paste(methods[i],".cfm",sep=""))
    if(matx$overall['Accuracy']>best){
      
       best<-matx$overall['Accuracy']
       meth<-methods[i]
    }
    summy
}

outtext<-paste("The best method tried is ",meth," with an accuracy of ",round(best,3),".\n"")
cat(outtext)
```

## Out of sample performance of the `r meth ` method 

The best scoring method ( `r meth` ) is applied to the test data. From this determine the _*out of sample error*_ for the model.

```{r}

bestMdlFile = paste(meth,".mdl",sep="")
load(bestMdlFile)

oof<-reduced_testSet[,-ncol(reduced_testSet)]
predicted<-predict(trainedModel,newdata=oof)
testKeys<-testSet[,ncol(testSet)]
falsecalls<-sum(predicted != testKeys)
matx<-confusionMatrix(predicted,testKeys)

v<-paste(capture.output(matx),collapse="\n")

cat(v)
```


The out of sample error determined for this model (1 - accuracy, where accuracy reflects the performance of the model applied to the test set ) is __`r round(1 - matx$overall['Accuracy'],3)`__ .  

Application of this model to the auto_test data set gives the following prediction:  
```{r}
predicted<-predict(trainedModel,newdata=auto_testPCA)
predicted
```
